{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from dataset.dataloader import *\n",
    "import operators as ops\n",
    "import torch\n",
    "import os\n",
    "\n",
    "CKPT_DIR = \"./logs/checkpoints\"\n",
    "LOAD_PRETRAINED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class torch_VGG8(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(torch_VGG8, self,).__init__()\n",
    "        # Layer 1 (B, 1, 28, 28) -> (B, 32, 28, 28)\n",
    "        self.Layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Layer 2 (B, 32, 28, 28) -> (B, 64, 14, 14)\n",
    "        self.Layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # Layer 3 (B, 64, 14, 14) -> (B, 64, 14, 14)\n",
    "        self.Layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Layer 4 (B, 64, 14, 14) -> (B, 128, 7, 7)\n",
    "        self.Layer4 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        # Layer 5 (B, 128, 7, 7) -> (B, 256, 7, 7)\n",
    "        self.Layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Layer 6 (B, 256, 7, 7) -> (B, 256, 7, 7)\n",
    "        self.Layer6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Layer 7 (B, 256*7*7) -> (B, 256)\n",
    "        self.Layer7 = nn.Sequential(\n",
    "            nn.Linear(in_features=256*7*7, out_features=256, bias=True,),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # Layer 8 (B, 256) -> (B, 10)\n",
    "        self.Layer8 = nn.Sequential(\n",
    "            nn.Linear(in_features=256, out_features=10, bias=True,),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # L1~L6: Conv + ReLU + (MaxPool)\n",
    "        x = self.Layer1(x)\n",
    "        x = self.Layer2(x)\n",
    "        x = self.Layer3(x)\n",
    "        x = self.Layer4(x)\n",
    "        x = self.Layer5(x)\n",
    "        x = self.Layer6(x)\n",
    "        # L7: FC + ReLU\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.Layer7(x)\n",
    "        # L8: FC\n",
    "        x = self.Layer8(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG8:\n",
    "    def __init__(self):\n",
    "        self.criterion = ops.SoftmaxWithLoss()\n",
    "        self.conv_layers = [\n",
    "            # Layer 1 (B, 1, 28, 28) -> (B, 32, 28, 28)\n",
    "            ops.Conv2D(in_channels=1, out_channels=32, kernel_size=3, padding=1, stride=1, name=\"L1_C\"),\n",
    "            ops.ReLU(name=\"L1_R\"),\n",
    "\n",
    "            # Layer2 (B, 32, 28, 28) -> (B, 64, 14, 14)\n",
    "            ops.Conv2D(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1, name=\"L2_C\"),\n",
    "            ops.ReLU(name=\"L2_R\"),\n",
    "            ops.MaxPooling(kernel_size=2, stride=2, name=\"L2_M\"),\n",
    "            \n",
    "            # Layer 3 (B, 64, 14, 14) -> (B, 64, 14, 14)\n",
    "            ops.Conv2D(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, name=\"L3_C\"),\n",
    "            ops.ReLU(name=\"L3_R\"),\n",
    "\n",
    "            # Layer 4 (B, 64, 14, 14) -> (B, 128, 7, 7)\n",
    "            ops.Conv2D(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1, name=\"L4_C\"),\n",
    "            ops.ReLU(name=\"L4_R\"),\n",
    "            ops.MaxPooling(kernel_size=2, stride=2, name=\"L4_M\"),\n",
    "\n",
    "            # Layer 5 (B, 128, 7, 7) -> (B, 256, 7, 7)\n",
    "            ops.Conv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1, name=\"L5_C\"),\n",
    "            ops.ReLU(name=\"L5_R\"),\n",
    "\n",
    "            # Layer 6 (B, 256, 7, 7) -> (B, 256, 7, 7)\n",
    "            ops.Conv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1, name=\"L6_C\"),\n",
    "            ops.ReLU(name=\"L6_R\")\n",
    "        ]\n",
    "\n",
    "        # Layer 7 (B, 256*7*7) -> (B, 256)\n",
    "        self.fc_layers = [\n",
    "            ops.FullyConnected(in_feature=256*7*7, out_feature=256, name=\"L7_FC\"),\n",
    "            ops.ReLU(name=\"L7_R\"),\n",
    "\n",
    "        # Layer 8 (B, 256) -> (B, 10)\n",
    "            ops.FullyConnected(in_feature=256, out_feature=10, name=\"L8_FC\")\n",
    "        ]\n",
    "\n",
    "    def backprop(self, lr, m=None) -> None:\n",
    "        # Backward\n",
    "        #dout = self.criterion.backward(pred, label)\n",
    "        dout = self.criterion.backward()\n",
    "        for i in range(len(self.fc_layers)-1, -1, -1):\n",
    "            dout = self.fc_layers[i].backward(dout)\n",
    "        dout = dout.reshape(dout.shape[0], 256, 7, 7)\n",
    "        for i in range(len(self.conv_layers)-1, -1, -1):\n",
    "            dout = self.conv_layers[i].backward(dout)\n",
    "        # Update\n",
    "        for layer in self.conv_layers:\n",
    "            layer.update(lr, m)\n",
    "        for layer in self.fc_layers:\n",
    "            layer.update(lr, m)\n",
    "        return dout\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        i = 0\n",
    "        for layer in self.conv_layers:\n",
    "            i+=1\n",
    "            x = layer.forward(x) \n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def save(self, fileName: str):\n",
    "        with open(fileName, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    def load(self, fileName: str):\n",
    "        with open(fileName, \"rb\") as f:\n",
    "            self = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load L1 Weight:(torch.Size([32, 1, 3, 3]),(32, 1, 3, 3))\n",
      "Load L1 Bias((32,),torch.Size([32]))\n",
      "Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Load L2 Weight:(torch.Size([64, 32, 3, 3]),(64, 32, 3, 3))\n",
      "Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Load L2 Bias((64,),torch.Size([64]))\n",
      "Load L3 Weight:(torch.Size([64, 64, 3, 3]),(64, 64, 3, 3))\n",
      "Load L3 Bias((64,),torch.Size([64]))\n",
      "Load L4 Weight:(torch.Size([128, 64, 3, 3]),(128, 64, 3, 3))\n",
      "Load L4 Bias((128,),torch.Size([128]))\n",
      "Load L5 Weight:(torch.Size([256, 128, 3, 3]),(256, 128, 3, 3))\n",
      "Load L5 Bias((256,),torch.Size([256]))\n",
      "Load L6 Weight:(torch.Size([256, 256, 3, 3]),(256, 256, 3, 3))\n",
      "Load L6 Bias((256,),torch.Size([256]))\n",
      "Load L7 Weight:(torch.Size([256, 12544]),(12544, 256))\n",
      "Load L7 Bias((256,),torch.Size([256]))\n",
      "Load L8 Weight:(torch.Size([10, 256]),(256, 10))\n",
      "Load L8 Bias((10,),torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "if LOAD_PRETRAINED:\n",
    "    # Load pretrained weights from torch\n",
    "    torch_vgg8 = torch_VGG8()\n",
    "    torch_vgg8.load_state_dict(torch.load(\"torch_vgg8.pt\"))\n",
    "\n",
    "    for i, p in enumerate(torch_vgg8.Layer1.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L1 Weight:({p.shape},{model.conv_layers[0].W.shape})\")\n",
    "            model.conv_layers[0].W = p.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L1 Bias({model.conv_layers[0].b.shape},{p.shape})\")\n",
    "            model.conv_layers[0].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer2.parameters()):\n",
    "        print(torch_vgg8.Layer2)\n",
    "        if (i == 0):\n",
    "            print(f\"Load L2 Weight:({p.shape},{model.conv_layers[2].W.shape})\")\n",
    "            model.conv_layers[2].W = p.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L2 Bias({model.conv_layers[2].b.shape},{p.shape})\")\n",
    "            model.conv_layers[2].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer3.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L3 Weight:({p.shape},{model.conv_layers[5].W.shape})\")\n",
    "            model.conv_layers[5].W = p.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L3 Bias({model.conv_layers[5].b.shape},{p.shape})\")\n",
    "            model.conv_layers[5].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer4.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L4 Weight:({p.shape},{model.conv_layers[7].W.shape})\")\n",
    "            model.conv_layers[7].W = p.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L4 Bias({model.conv_layers[7].b.shape},{p.shape})\")\n",
    "            model.conv_layers[7].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer5.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L5 Weight:({p.shape},{model.conv_layers[10].W.shape})\")\n",
    "            model.conv_layers[10].W = p.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L5 Bias({model.conv_layers[10].b.shape},{p.shape})\")\n",
    "            model.conv_layers[10].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer6.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L6 Weight:({p.shape},{model.conv_layers[12].W.shape})\")\n",
    "            model.conv_layers[12].W = p.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L6 Bias({model.conv_layers[12].b.shape},{p.shape})\")\n",
    "            model.conv_layers[12].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer7.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L7 Weight:({p.shape},{model.fc_layers[0].W.shape})\")\n",
    "            model.fc_layers[0].W = p.T.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L7 Bias({model.fc_layers[0].b.shape},{p.shape})\")\n",
    "            model.fc_layers[0].b = p.detach().numpy()\n",
    "    for i, p in enumerate(torch_vgg8.Layer8.parameters()):\n",
    "        if (i == 0):\n",
    "            print(f\"Load L8 Weight:({p.shape},{model.fc_layers[2].W.shape})\")\n",
    "            model.fc_layers[2].W = p.T.detach().numpy()\n",
    "        else:\n",
    "            print(f\"Load L8 Bias({model.fc_layers[2].b.shape},{p.shape})\")\n",
    "            model.fc_layers[2].b = p.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(60000, 784), Test:(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "batch_size = 50\n",
    "learning_rate = 0.01\n",
    "#momentum = 0.9\n",
    "momentum = None\n",
    "loss_print_time = 5\n",
    "accuracy_print_time = loss_print_time * 5\n",
    "x_log = []\n",
    "loss_log = []\n",
    "\n",
    "print(f\"Train:{x_train.shape}, Test:{x_test.shape}\")\n",
    "\n",
    "def accuracy_check(model, x_test, t_test, test_size):\n",
    "    total_correct = 0\n",
    "\n",
    "    test_data_idx = np.random.choice(x_test.shape[0], test_size)\n",
    "    for i in tqdm(test_data_idx):\n",
    "        x = x_test[i].reshape(1, 1, 28, 28)\n",
    "        labels = t_test[i]\n",
    "\n",
    "        outputs = model.forward(x)\n",
    "        labels = labels.reshape(outputs.shape)\n",
    "        c = (np.argmax(labels, 1) == np.argmax(outputs, 1)).squeeze()\n",
    "        total_correct += np.sum(c)\n",
    "    return total_correct/test_size\n",
    "    #print(f\"Accuracy:{total_correct/test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 82.71it/s]\n",
      "1it [00:02,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:0, data num:0] Avg Loss: 2.200621, Max Loss: 2.200621, Min Loss: 2.200621, Accuracy: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:07,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:0, data num:250] Avg Loss: 2.166489, Max Loss: 2.195075, Min Loss: 2.137614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:12,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:0, data num:500] Avg Loss: 2.123064, Max Loss: 2.181011, Min Loss: 2.046674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:0, data num:750] Avg Loss: 1.948016, Max Loss: 2.035387, Min Loss: 1.856344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:21,  1.06s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    accuracy = 0.0\n",
    "    train_size = x_train.shape[0]\n",
    "    running_loss = []\n",
    "    for i, b in tqdm(enumerate(range(0, train_size, batch_size))):\n",
    "        x = x_train[b:b+batch_size].reshape(batch_size, 1, 28, 28)   # B, C, H, W\n",
    "        labels = t_train[b:b+batch_size]\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        outputs = model.forward(x)\n",
    "        loss = model.criterion.forward(outputs, labels)\n",
    "        running_loss.append(loss)\n",
    "        model.backprop(learning_rate, momentum)\n",
    "\n",
    "        if (i % loss_print_time == 0):\n",
    "            if (i % accuracy_print_time == 0):\n",
    "                print(f'[epoch:{epoch}, data num:{b}] Avg Loss: {sum(running_loss)/len(running_loss):.6f}, Max Loss: {max(running_loss):.6f}, Min Loss: {min(running_loss):.6f}, Accuracy: {accuracy_check(model, x_test, t_test, 100)}')\n",
    "            else:\n",
    "                print(f'[epoch:{epoch}, data num:{b}] Avg Loss: {sum(running_loss)/len(running_loss):.6f}, Max Loss: {max(running_loss):.6f}, Min Loss: {min(running_loss):.6f}')\n",
    "            loss_log += running_loss\n",
    "            running_loss = []\n",
    "            #model.save(os.path.join(CKPT_DIR, \"epoch_%03d_%06d.pkl\" % (epoch, i) ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/anaconda3/envs/torch/lib/python3.8/site-packages/numpy/core/shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  ary = asanyarray(ary)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23690/780749636.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2757\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2758\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2281\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2285\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'_child{len(self._children)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   2304\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m         \"\"\"\n\u001b[0;32m-> 2306\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0;34m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0myconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_yunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvdmJKk9Zoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z+aSSpHWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WVQ22RI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuE2fcLEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZculjwdYoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(loss_log)), loss_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 95.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(t_train.shape)\n",
    "batch_size = 200\n",
    "total_correct = 0\n",
    "\n",
    "running_loss = 0.0\n",
    "accuracy = 0.0\n",
    "test_size = 1000\n",
    "test_data_idx = np.random.choice(x_test.shape[0], test_size)\n",
    "for i in tqdm(test_data_idx):\n",
    "    x = x_test[i].reshape(1, 1, 28, 28)\n",
    "    labels = t_test[i]\n",
    "\n",
    "    outputs = model.forward(x)\n",
    "    labels = labels.reshape(outputs.shape)\n",
    "    c = (np.argmax(labels, 1) == np.argmax(outputs, 1)).squeeze()\n",
    "    total_correct += np.sum(c)\n",
    "\n",
    "print(f\"Accuracy:{total_correct/test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8685447846838947],\n",
       " [0.974748666638959,\n",
       "  0.70904474799902,\n",
       "  0.668387099380597,\n",
       "  0.9311568231315739,\n",
       "  0.9875813066419978,\n",
       "  0.9915942063026881,\n",
       "  0.7446414217855859,\n",
       "  0.8947772223060129,\n",
       "  0.914543999091713,\n",
       "  0.9125938993230096],\n",
       " [0.8542537324420817,\n",
       "  0.9130112428504628,\n",
       "  0.8419847191524624,\n",
       "  0.8368279579901851,\n",
       "  0.8804089419473665,\n",
       "  0.609895316563449,\n",
       "  0.5561483046388399,\n",
       "  0.6553142597060525,\n",
       "  0.6455818801577512,\n",
       "  0.7925676214731671],\n",
       " [0.4985794771424321,\n",
       "  0.63666482679869,\n",
       "  0.6951424256149558,\n",
       "  0.8042707863844143,\n",
       "  0.6143679984843363,\n",
       "  0.7196892863942425,\n",
       "  0.5677317507957054,\n",
       "  0.5302071605023799,\n",
       "  0.6476010124671572,\n",
       "  0.8715506144267248],\n",
       " [0.5278156262446533,\n",
       "  0.7280703892433478,\n",
       "  0.782962269305691,\n",
       "  0.5702488688992853,\n",
       "  0.6772801757678256,\n",
       "  0.6081562258422408,\n",
       "  0.6564509080865171,\n",
       "  0.5564604636985427,\n",
       "  0.5169910944569097,\n",
       "  0.5875863641408327],\n",
       " [0.7001660992792712,\n",
       "  0.47507111945156255,\n",
       "  0.6586058980074996,\n",
       "  0.515630680694363,\n",
       "  0.5009723883074932,\n",
       "  0.672733357941534,\n",
       "  0.5255367822450809,\n",
       "  0.5017626261101619,\n",
       "  0.6799109553932816,\n",
       "  0.5997423791035557],\n",
       " [0.8195159450306408,\n",
       "  0.4901622573452874,\n",
       "  0.6491917579168858,\n",
       "  0.39979708556455895,\n",
       "  0.5711064186840349,\n",
       "  0.6261790637966278,\n",
       "  0.5184074913724633,\n",
       "  0.7344823969628549,\n",
       "  0.5691499529922559,\n",
       "  0.36900129118225033],\n",
       " [0.43774359049930234,\n",
       "  0.5489086265523554,\n",
       "  0.47166264326043456,\n",
       "  0.500605556036187,\n",
       "  0.3715951589172402,\n",
       "  0.4360119124038652,\n",
       "  0.4522864451783932,\n",
       "  0.6713237108291829,\n",
       "  0.5518762975324394,\n",
       "  0.6576117723086294],\n",
       " [0.5696501535440462,\n",
       "  0.90022077240611,\n",
       "  0.6451743458619811,\n",
       "  0.4544954793404039,\n",
       "  0.5311767882754796,\n",
       "  0.6528361683591883,\n",
       "  0.5394491863105071,\n",
       "  0.6139853572634227,\n",
       "  0.5505358961931186,\n",
       "  0.4478439885751272],\n",
       " [0.5469990362172157,\n",
       "  0.788938697878266,\n",
       "  0.476073030258152,\n",
       "  0.673767565544514,\n",
       "  0.3436823062830678,\n",
       "  0.7084252217536813,\n",
       "  0.8150306596773313,\n",
       "  0.7978815620802528,\n",
       "  0.4885728838082278,\n",
       "  0.37451598432911615],\n",
       " [0.5236986641644031,\n",
       "  0.5634192263537495,\n",
       "  0.5003391347251257,\n",
       "  0.4781597625815616,\n",
       "  0.56719162310232,\n",
       "  0.4386463000529258,\n",
       "  0.471536582467799,\n",
       "  0.40838987434440244,\n",
       "  0.35592278493421603,\n",
       "  0.48077944325334854],\n",
       " [0.43650892749401293,\n",
       "  0.7778774259873351,\n",
       "  0.3400438166058939,\n",
       "  0.34679148005070104,\n",
       "  0.3965215277531501,\n",
       "  0.3895398465226451,\n",
       "  0.6977036729636782,\n",
       "  0.3329554093910073,\n",
       "  0.49428392714987707,\n",
       "  0.3856976734544312]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a7cdbdf4acc413f2026664a4e43a97e227e5467d9e60d879c8298bb8a0c0924"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
