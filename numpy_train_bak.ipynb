{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from dataset.dataloader import *\n",
    "import operators as ops\n",
    "import os\n",
    "\n",
    "CKPT_DIR = \"./logs/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG8:\n",
    "    def __init__(self):\n",
    "        self.criterion = ops.SoftmaxWithLoss()\n",
    "        self.conv_layers = [\n",
    "            # Layer 1 (B, 1, 28, 28) -> (B, 32, 28, 28)\n",
    "            ops.Conv2D(in_channels=1, out_channels=32, kernel_size=3, padding=1, stride=1, name=\"L1_C\"),\n",
    "            ops.ReLU(name=\"L1_R\"),\n",
    "\n",
    "            # Layer2 (B, 32, 28, 28) -> (B, 64, 14, 14)\n",
    "            ops.Conv2D(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=1, name=\"L2_C\"),\n",
    "            ops.ReLU(name=\"L2_R\"),\n",
    "            ops.MaxPooling(kernel_size=2, stride=2, name=\"L2_M\"),\n",
    "            \n",
    "            # Layer 3 (B, 64, 14, 14) -> (B, 64, 14, 14)\n",
    "            ops.Conv2D(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1, name=\"L3_C\"),\n",
    "            ops.ReLU(name=\"L3_R\"),\n",
    "\n",
    "            # Layer 4 (B, 64, 14, 14) -> (B, 128, 7, 7)\n",
    "            ops.Conv2D(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1, name=\"L4_C\"),\n",
    "            ops.ReLU(name=\"L4_R\"),\n",
    "            ops.MaxPooling(kernel_size=2, stride=2, name=\"L4_M\"),\n",
    "\n",
    "            # Layer 5 (B, 128, 7, 7) -> (B, 256, 7, 7)\n",
    "            ops.Conv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1, name=\"L5_C\"),\n",
    "            ops.ReLU(name=\"L5_R\"),\n",
    "\n",
    "            # Layer 6 (B, 256, 7, 7) -> (B, 256, 7, 7)\n",
    "            ops.Conv2D(in_channels=256, out_channels=256, kernel_size=3, padding=1, stride=1, name=\"L6_C\"),\n",
    "            ops.ReLU(name=\"L6_R\")\n",
    "        ]\n",
    "\n",
    "        # Layer 7 (B, 256*7*7) -> (B, 256)\n",
    "        self.fc_layers = [\n",
    "            ops.FullyConnected(in_feature=256*7*7, out_feature=256, name=\"L7_FC\"),\n",
    "            ops.ReLU(name=\"L7_R\"),\n",
    "\n",
    "        # Layer 8 (B, 256) -> (B, 10)\n",
    "            ops.FullyConnected(in_feature=256, out_feature=10, name=\"L8_FC\")\n",
    "        ]\n",
    "\n",
    "    def backprop(self, pred: np.ndarray, label: np.ndarray, lr) -> None:\n",
    "        # Backward\n",
    "        #dout = self.criterion.backward(pred, label)\n",
    "        dout = self.criterion.backward(1)\n",
    "        for i in range(len(self.fc_layers)-1, -1, -1):\n",
    "            dout = self.fc_layers[i].backward(dout)\n",
    "        dout = dout.reshape(dout.shape[0], 256, 7, 7)\n",
    "        for i in range(len(self.conv_layers)-1, -1, -1):\n",
    "            dout = self.conv_layers[i].backward(dout)\n",
    "        # Update\n",
    "        for layer in self.conv_layers:\n",
    "            layer.update(lr)\n",
    "        for layer in self.fc_layers:\n",
    "            layer.update(lr)\n",
    "        return dout\n",
    "\n",
    "    def forward(self, x: np.ndarray):\n",
    "        i = 0\n",
    "        for layer in self.conv_layers:\n",
    "            i+=1\n",
    "            x = layer.forward(x) \n",
    "            #print(x[0])\n",
    "            if ((x[0] == x[1]).all() and (x[0] == x[-1]).all()):\n",
    "                print(f\"[{layer.name}] {x[0]}\")\n",
    "                break\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer.forward(x)\n",
    "            if ((x[0] == x[1]).all()):\n",
    "                print(f\"[{layer.name}]\")\n",
    "                break\n",
    "        return x\n",
    "\n",
    "    def save(self, fileName: str):\n",
    "        with open(fileName, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    def load(self, fileName: str):\n",
    "        with open(fileName, \"rb\") as f:\n",
    "            self = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "batch_size = 2\n",
    "learning_rate = 0.01\n",
    "loss_print_time = batch_size * 10\n",
    "x_log = []\n",
    "loss_log = []\n",
    "\n",
    "print(f\"Train:{x_train.shape}, Test:{x_test.shape}\")\n",
    "for i in x_train[0]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(10):\n",
    "    accuracy = 0.0\n",
    "    train_size = x_train.shape[0]\n",
    "    running_loss = 0.0\n",
    "    for i in tqdm(range(0, train_size, batch_size)):\n",
    "        x = x_train[i:i+batch_size].reshape(batch_size, 1, 28, 28)   # B, C, H, W\n",
    "        labels = t_train[i:i+batch_size]\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        outputs = ops.Softmax(model.forward(x))\n",
    "        #print(outputs)\n",
    "        labels = labels\n",
    "        loss = model.criterion.forward(outputs, labels)\n",
    "        running_loss += loss\n",
    "        model.backprop(outputs, labels, learning_rate)\n",
    "\n",
    "        if (i % loss_print_time == 0):\n",
    "            #running_loss /= loss_print_time\n",
    "            print(f'[epoch:{epoch}, data num:{i}] loss: {running_loss}')\n",
    "            x_log.append(i)\n",
    "            loss_log.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "            #model.save(os.path.join(CKPT_DIR, \"epoch_%03d_%06d.pkl\" % (epoch, i) ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_log, loss_log)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_train.shape)\n",
    "batch_size = 200\n",
    "total_correct = 0\n",
    "\n",
    "running_loss = 0.0\n",
    "accuracy = 0.0\n",
    "test_size = 1000\n",
    "test_data_idx = np.random.choice(x_test.shape[0], test_size)\n",
    "for i in tqdm(test_data_idx):\n",
    "    x = x_test[i].reshape(1, 1, 28, 28)\n",
    "    labels = t_test[i]\n",
    "\n",
    "    outputs = model.forward(x)\n",
    "    labels = labels.reshape(outputs.shape)\n",
    "    c = (np.argmax(labels, 1) == np.argmax(outputs, 1)).squeeze()\n",
    "    total_correct += np.sum(c)\n",
    "\n",
    "print(f\"Accuracy:{total_correct/test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a7cdbdf4acc413f2026664a4e43a97e227e5467d9e60d879c8298bb8a0c0924"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
