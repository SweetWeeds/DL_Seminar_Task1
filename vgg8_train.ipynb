{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.dataloader import load_mnist\n",
    "from common.vgg8 import VGG8\n",
    "from common.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300341909704695\n",
      "=== epoch:1, train acc:0.094, test acc:0.087 ===\n",
      "train loss:2.2985496976841353\n",
      "train loss:2.2990569964224012\n",
      "train loss:2.30056531838273\n",
      "train loss:2.2886137864564544\n",
      "train loss:2.2917414521383863\n",
      "train loss:3.4595619054787075\n",
      "train loss:2.29861084185376\n",
      "train loss:2.307863732568434\n",
      "train loss:2.3052851519565873\n",
      "train loss:2.2960192795049763\n",
      "train loss:2.303689661940149\n",
      "train loss:2.2989311664910073\n",
      "train loss:2.303990768556826\n",
      "train loss:2.304707239841456\n",
      "train loss:2.3021798272211487\n",
      "train loss:2.296808936109665\n",
      "train loss:2.2987690227519404\n",
      "train loss:2.3019811677677358\n",
      "train loss:2.287821354274748\n",
      "train loss:2.2848506256219934\n",
      "train loss:2.287746420553342\n",
      "train loss:2.3073628409359954\n",
      "train loss:2.3062661803080977\n",
      "train loss:2.2989680887474027\n",
      "train loss:2.2986807690386626\n",
      "train loss:2.306258299385442\n",
      "train loss:2.3035062094155396\n",
      "train loss:2.30152907234454\n",
      "train loss:2.300242954662632\n",
      "train loss:2.3016065640048917\n",
      "train loss:2.3124665126477346\n",
      "train loss:2.3001826921033186\n",
      "train loss:2.2968860309549157\n",
      "train loss:2.3097355242865536\n",
      "train loss:2.2992819351955767\n",
      "train loss:2.2985570564507016\n",
      "train loss:2.296216437878353\n",
      "train loss:2.2990864861381732\n",
      "train loss:2.3092338285692535\n",
      "train loss:2.303544739041395\n",
      "train loss:2.297757968066479\n",
      "train loss:2.288854087574714\n",
      "train loss:2.3108166729516157\n",
      "train loss:2.3065585803769637\n",
      "train loss:2.294652589946115\n",
      "train loss:2.298441153593746\n",
      "train loss:2.3013899087801115\n",
      "train loss:2.297322758396202\n",
      "train loss:2.3084155777135233\n",
      "train loss:2.3108297621131193\n",
      "train loss:2.301623558551476\n",
      "train loss:2.3067355561004006\n",
      "train loss:2.3047299203202343\n",
      "train loss:2.297675870414719\n",
      "train loss:2.3000311964408966\n",
      "train loss:2.303076508407326\n",
      "train loss:2.304773355559604\n",
      "train loss:2.300770173980708\n",
      "train loss:2.3067457705586114\n",
      "train loss:2.2977205049144542\n",
      "train loss:2.2973579874914063\n",
      "train loss:2.3061152109350083\n",
      "train loss:2.3007556912384213\n",
      "train loss:2.2896888292372015\n",
      "train loss:2.291423873755362\n",
      "train loss:2.3061766994649107\n",
      "train loss:2.29996893241253\n",
      "train loss:2.303516718915433\n",
      "train loss:2.3006347205269964\n",
      "train loss:2.308934788035988\n",
      "train loss:2.2977540364018423\n",
      "train loss:2.3001019640524123\n",
      "train loss:2.309985371421517\n",
      "train loss:2.301203876616784\n",
      "train loss:2.2901410134269935\n",
      "train loss:2.306090461519109\n",
      "train loss:2.31198323034632\n",
      "train loss:2.2983770191891733\n",
      "train loss:2.2955942856721117\n",
      "train loss:2.3092301071032404\n",
      "train loss:2.304774792702962\n",
      "train loss:2.3094382552812847\n",
      "train loss:2.31391524581802\n",
      "train loss:2.308029627406724\n",
      "train loss:2.303344501213272\n",
      "train loss:2.2941824311560044\n",
      "train loss:2.2909393035569288\n",
      "train loss:2.301831130751283\n",
      "train loss:2.292366379478435\n",
      "train loss:2.3055488750307576\n",
      "train loss:2.3021193344267674\n",
      "train loss:2.2894454080109163\n",
      "train loss:2.311071380817904\n",
      "train loss:2.2959747374635966\n",
      "train loss:2.311962306525122\n",
      "train loss:2.303979777604967\n",
      "train loss:2.3040481551783727\n",
      "train loss:2.301377074704827\n",
      "train loss:2.3051765000800652\n",
      "train loss:2.3036151220764207\n",
      "train loss:2.302228758534512\n",
      "train loss:2.2995359829831994\n",
      "train loss:2.2908070933941143\n",
      "train loss:2.304184558611744\n",
      "train loss:2.3038144636781337\n",
      "train loss:2.295879376024736\n",
      "train loss:2.3057561471668206\n",
      "train loss:2.3005935274357934\n",
      "train loss:2.309567227695823\n",
      "train loss:2.29716327940693\n",
      "train loss:2.2918800951422247\n",
      "train loss:2.308857401511035\n",
      "train loss:2.289867515712341\n",
      "train loss:2.300957706751271\n",
      "train loss:2.306790668280846\n",
      "train loss:2.299548039079208\n",
      "train loss:2.2940021877031653\n",
      "train loss:2.304251743000289\n",
      "train loss:2.2978911253961125\n",
      "train loss:2.290421135507357\n",
      "train loss:2.295342635813179\n",
      "train loss:2.3005177269124446\n",
      "train loss:2.2853491295969963\n",
      "train loss:2.3053225498690724\n",
      "train loss:2.299272461057576\n",
      "train loss:2.3010995239598935\n",
      "train loss:2.3102012612557687\n",
      "train loss:2.3070410634118574\n",
      "train loss:2.302824481350527\n",
      "train loss:2.3115308449223013\n",
      "train loss:2.294247007681382\n",
      "train loss:2.294650231102014\n",
      "train loss:2.297541747883821\n",
      "train loss:2.299370666997374\n",
      "train loss:2.3032394509335665\n",
      "train loss:2.2888612233931274\n",
      "train loss:2.3122933119353473\n",
      "train loss:2.3013418771920557\n",
      "train loss:2.3109971135082517\n",
      "train loss:2.300624235950669\n",
      "train loss:2.2877610335665715\n",
      "train loss:2.3094364993263348\n",
      "train loss:2.3117190220767947\n",
      "train loss:2.303758211369488\n",
      "train loss:2.290420491105563\n",
      "train loss:2.2978733576490815\n",
      "train loss:2.2898783700088443\n",
      "train loss:2.299154071754716\n",
      "train loss:2.2986398479421064\n",
      "train loss:2.2973737999731347\n",
      "train loss:2.295613499122594\n",
      "train loss:2.308046550313537\n",
      "train loss:2.2948931675867446\n",
      "train loss:2.3106921083379173\n",
      "train loss:2.2963480249639487\n",
      "train loss:2.3043545998366404\n",
      "train loss:2.2995896937016576\n",
      "train loss:2.296345888776103\n",
      "train loss:2.309084143371597\n",
      "train loss:2.3066994594411057\n",
      "train loss:2.2922541186691245\n",
      "train loss:2.304740506099089\n",
      "train loss:2.3096829486998662\n",
      "train loss:2.2996129491919586\n",
      "train loss:2.3016233064104212\n",
      "train loss:2.3066344124800695\n",
      "train loss:2.2977657835755303\n",
      "train loss:2.3008155512533723\n",
      "train loss:2.307332574237195\n",
      "train loss:2.295175574230036\n",
      "train loss:2.299688089806329\n",
      "train loss:2.3016129655135873\n",
      "train loss:2.305762286699844\n",
      "train loss:2.29307819057601\n",
      "train loss:2.3020988041990806\n",
      "train loss:2.304270784283793\n",
      "train loss:2.287810165580163\n",
      "train loss:2.3112107495332723\n",
      "train loss:2.310163501758641\n",
      "train loss:2.297799204152097\n",
      "train loss:2.300921592636083\n",
      "train loss:2.2782189717130112\n",
      "train loss:2.303416295323635\n",
      "train loss:2.308819719557431\n",
      "train loss:2.2995767782174092\n",
      "train loss:2.2993920386926585\n",
      "train loss:2.28805010196994\n",
      "train loss:2.2943306957853062\n",
      "train loss:2.3149384554055548\n",
      "train loss:2.297536121806724\n",
      "train loss:2.309937408572541\n",
      "train loss:2.3147760003101343\n",
      "train loss:2.3009790620415367\n",
      "train loss:2.3030421211391587\n",
      "train loss:2.3151100641850526\n",
      "train loss:2.293651437088935\n",
      "train loss:2.292675565719194\n",
      "train loss:2.315044361817192\n",
      "train loss:2.29071631550311\n",
      "train loss:2.3118568832838973\n",
      "train loss:2.3109709885128966\n",
      "train loss:2.2934934824848083\n",
      "train loss:2.302762352165333\n",
      "train loss:2.2998002815134946\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model,\n",
    "                    x_train, t_train,\n",
    "                    x_test, t_test,\n",
    "                    epochs=1000, mini_batch_size=100,\n",
    "                    optimizer='Momentum', optimizer_param={'lr':0.01, 'momentum'=0.9},\n",
    "                    evaluate_sample_num_per_epoch=1000\n",
    "                )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a7cdbdf4acc413f2026664a4e43a97e227e5467d9e60d879c8298bb8a0c0924"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
